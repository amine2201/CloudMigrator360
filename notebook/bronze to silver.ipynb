{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/mnt/bronze/SalesLT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/mnt/silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path='/mnt/bronze/SalesLT/Address/Address.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('parquet').load(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_utc_timestamp, date_format\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "df = df.withColumn('ModifiedDate', date_format(from_utc_timestamp(df['ModifiedDate'].cast(TimestampType()), 'UTC'), 'yyyy-MM-dd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%md \n",
    "Transforming all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name=[]\n",
    "for i in dbutils.fs.ls(\"/mnt/bronze/SalesLT\"):\n",
    "  table_name.append(i.name.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_utc_timestamp, date_format\n",
    "from pyspark.sql.types import TimestampType\n",
    "\n",
    "for i in table_name:\n",
    "    path='/mnt/bronze/SalesLT/'+i+'/'+i+'.parquet'\n",
    "    df = spark.read.format('parquet').load(path)\n",
    "    columns=df.columns\n",
    "\n",
    "    for col in columns:\n",
    "        if \"Date\" in col or \"date\" in col:\n",
    "            df = df.withColumn(col, date_format(from_utc_timestamp(df[col].cast(TimestampType()), 'UTC'), 'yyyy-MM-dd'))\n",
    "\n",
    "    output_path='/mnt/silver/SalesLT/'+i+'/'\n",
    "    df.write.format('delta').mode('overwrite').save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
